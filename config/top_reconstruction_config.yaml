root_dataset_prepper:
  root_path: "data/topquarkreconstruction/root_data"
  save_path: "data/topquarkreconstruction/h5py_data"
  train_file_name:  "ttbar_train"
  val_file_name: "ttbar_val"
  test_file_name: "ttbar_test"
  save_file_prefix: "ttbar_h5py_raw_"


preprocessing:
  stream_size: 200000
  save_path: "data/topquarkreconstruction/processed_data_interaction_with_W"
  save_file_prefix: "ttbar_preprocessed_"

interactions: 
  True
reconstruct_W:
  hungarian: False
  True



data_modules:
  input_path: data/topquarkreconstruction/processed_data_interaction_with_W
  input_prefix: "ttbar_preprocessed_"

  train:
    batch_size: 1024
    shuffle: True
    num_workers: 1
    pin_memory: True
  test:
    batch_size: 2024
    shuffle: False
    num_workers: 1
    pin_memory: False
  val:
    batch_size: 2024
    shuffle: False
    num_workers: 1
    pin_memory: False

model_parameters:
  particle_embedder:
    n_input: 7
    hidden_sizes: [64, 128]
    embedding_size: 64
    p_dropout: 0.1
  

  interaction_embedder:
    input_features: 4
    hidden_layers: [64, 64, 64]
    output_size: 8
    p_dropout: 0.1

  transformer:
    embedding_size: 64
    n_encoder_layers: 8
    n_decoder_layers: 2
    n_heads: 8
    out_dimensions: 5
    p_dropout: 0.1
    dim_ff: 256

  reverse_embedder:
    n_input: 64
    hidden_sizes: [128, 64]
    output_size: 5
    p_dropout: 0.1

model_training:
  learning_rate: 0.0005
  weight_decay: 0.001
  use_lookahead : True
  min_epochs: 5
  max_epochs: 20
  
model_artefacts:
  reverse_target_transformers: "data/topquarkreconstruction/processed_data/target_transformed.joblib"
  reverse_W_transformer: 